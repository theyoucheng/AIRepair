{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py.eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28353/1116583600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# personal modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#from distance_metrics import bhattacharyya\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_eval_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m from py.layer_selection import (Forward_Layer_Select, \n\u001b[1;32m     40\u001b[0m                                 \u001b[0mcalculate_acc_for_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py.eval'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "import os\n",
    "from keras import regularizers\n",
    "batch_size = 128  \n",
    "epochs = 200\n",
    "regu= 0.0003             ## regularization weight\n",
    "num_layer= 30            ## number of layers in ResNet, it should satisfy num_layer= 6*n +2 where n is an integer\n",
    "                         ## if not, num_layer will be converted to a number satisfying 6*n+2 \n",
    "n= int((num_layer-2)/6)\n",
    "\n",
    "\n",
    "# plot defaults\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer\n",
    "https://keras.io/getting-started/faq/#how-can-i-freeze-keras-layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting Threshold\n",
    "# Both the training accuracy (TrAcc)  and the testing accuracy (TeAcc)\n",
    "# must be lower than this param to qualify as underfitting\n",
    "theta = 0.92\n",
    "\n",
    "# Overfitting Threshold\n",
    "# The difference between the training accuracy (TrAcc) and testing accuracy (TeAcc)\n",
    "# must be larger than this param to qualify as overfitting\n",
    "gamma = 0.10\n",
    "\n",
    "# Ratio between Selected Data and Random Data \n",
    "# Controls the ratio of the target class to fix and the random other classes \n",
    "# trained simultaneosly. \n",
    "# TODO: find a way to experiment with setting this automatically based on the \n",
    "# number of classes in your task. \n",
    "# TODO: see if we can use larger alpha and reduced batch sizes to control overfitting\n",
    "alpha = 0.25\n",
    "\n",
    "# Byattacharyya Distance\n",
    "# If the distribution of two y_pred matrices are less than this amount, than they are\n",
    "# sufficiently similar and we'll take the layer that produced the distribution first\n",
    "similarity_threshold = 0.01\n",
    "\n",
    "# Number of Epochs\n",
    "# TODO: implement early stopping\n",
    "epochs = 3\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 2000 # they used 2000 and 4000 in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "# split into test and train sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize to [0,1] by dividing by the max value\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# further split x_train and y_train into new training and bug fixing sets (50/50)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_bug_fixes, y_train, y_bug_fixes = train_test_split(x_train, y_train, test_size=0.5, random_state=123)\n",
    "\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "\n",
    "print('Bug Fixing data shape: ', x_bug_fixes.shape)\n",
    "print('Bug Fixing labels shape: ', y_bug_fixes.shape)\n",
    "\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that will be the one evaluated and retrained using MODE input selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, filters, f = 3, s= 2):\n",
    "    \"\"\"\n",
    "    convolutional block    H and W shrink by half due to stride =2 after the convolutional block\n",
    "    \n",
    "    H=H_prev/2, W=W_prev/2 with stride=2\n",
    "    \n",
    "    Inputs:\n",
    "    X -- input tensor (m, H_prev, W_prev, C_prev)\n",
    "    filters -- the number of filters\n",
    "    f -- filter size is (f, f)\n",
    "    s -- stride\n",
    "    Outputs:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the input value for later\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First layer of main path \n",
    "    X = Conv2D(filters, (f, f), strides = (s,s), padding = 'same', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer of main path \n",
    "    X = Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    # First layer of the shortcut path\n",
    "    X_shortcut = Conv2D(filters, (1, 1), strides = (s,s), padding = 'same', kernel_initializer = glorot_uniform())(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
    "\n",
    "    # Add shortcut value to main path\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "        \n",
    "    return X\n",
    "def identity_block(X, filters, f=3):\n",
    "    \"\"\" identity block    H and W is unchaged before and after identity block\n",
    "    Inputs:\n",
    "    X -- input tensor (m, H_prev, W_prev, C_prev)\n",
    "    filters -- the number of filters\n",
    "    f -- filter size is (f, f)\n",
    "    \n",
    "    Output:\n",
    "    X -- output tensor (H, W, C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the input value for later\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First layer of main path\n",
    "    X = Conv2D(filters = filters, kernel_size = (f, f), strides = (1,1),kernel_regularizer=regularizers.l2(regu), padding = 'same', kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer of main path\n",
    "    X = Conv2D(filters = filters, kernel_size = (f, f), strides = (1,1), kernel_regularizer=regularizers.l2(regu), padding = 'same', kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    # Add shortcut value to main path\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "def ResNet(input_shape = (32, 32, 3), classes = 10, n=3):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    input_shape -- shape of the images of the dataset (H=32, W=32, C=3)\n",
    "    classes -- number of classes\n",
    "    n -- number of blocks in each stage\n",
    "    \n",
    "    Outputs:\n",
    "    model -- a Model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct an input tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Padding\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    \n",
    "    ## output size 32 by 32, 16 filters\n",
    "    \n",
    "    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Stage 2  output size 32 by 32, 16 filters\n",
    "    X = identity_block(X, filters = 16)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 16)\n",
    "\n",
    "    # Stage 3 output size 16 by 16, 32 filters \n",
    "    X = convolutional_block(X, filters = 32)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 32)\n",
    "    \n",
    "\n",
    "    # Stage 4 output size 8 by 8, 64 filters\n",
    "    X = convolutional_block(X, filters = 64)\n",
    "    for i in range(n-1):\n",
    "        X = identity_block(X, filters = 64)\n",
    "    \n",
    "    # Stage 5, averagepooling, output size (1, 1, 64)\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(8, 8), strides=None, name=\"avg_pool\")(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_regularizer=regularizers.l2(regu), kernel_initializer = glorot_uniform())(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet')\n",
    "\n",
    "    return model\n",
    "model = ResNet(input_shape = (32, 32, 3), classes = 10, n= 3)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "# split into test and train sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize to [0,1] by dividing by the max value\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "modelname=\"ResNet_l\"+str(num_layer)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train (to get distributions)\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "# predict test (to get distributions)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final train\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print('Train Loss: {}, Train Accuracy: {}'.format(train_loss, train_acc))\n",
    "\n",
    "# test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test Loss: {}, Test Accuracy: {}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model that will be retrained on a similar amount of data but as our main model, but the data is chosen at random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_model = replicate_model(model)\n",
    "\n",
    "control_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# control_model.build()\n",
    "# control_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeting Problematic Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_target_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer, cache = Forward_Layer_Select(model, \n",
    "                                           x_train, \n",
    "                                           y_train, \n",
    "                                           x_test, \n",
    "                                           y_test, \n",
    "                                           epochs, \n",
    "                                           similarity_threshold, \n",
    "                                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_models, accuracies, bhattacharyyas, layer_pred = cache\n",
    "\n",
    "get_plot(accuracies, \n",
    "         title='Number of Layers and Accuracy',\n",
    "         xlabel='Number of layers',\n",
    "         ylabel='Accuracy')\n",
    "\n",
    "get_plot(bhattacharyyas, \n",
    "         title='Number of Layers and Bhattacharyya Similarity',\n",
    "         xlabel='Number of layers',\n",
    "         ylabel='Bhattacharyya Similarity')\n",
    "\n",
    "visualize_array(target_layer.get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: _o means correct and _x means incorrect and can be read as\n",
    "#       \"for those that were incorrectly classified\"\n",
    "\n",
    "out = get_eval_datasets(data = x_train, \n",
    "                        labels = y_train, \n",
    "                        predictions = y_pred_train)\n",
    "\n",
    "x_train_o, y_pred_train_o, x_train_x, y_pred_train_x, y_true_train_x = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_per_label_train = calculate_acc_for_labels(all_labels = y_train,\n",
    "                                                      correct_labels = y_pred_train_o,\n",
    "                                                      num_classes = 10,\n",
    "                                                      labels = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_per_label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: _o means correct and _x means incorrect and can be read as\n",
    "#       \"for those that were incorrectly classified\"\n",
    "\n",
    "out = get_eval_datasets(data = x_test, \n",
    "                        labels = y_test, \n",
    "                        predictions = y_pred)\n",
    "\n",
    "x_test_o, y_pred_o, x_test_x, y_pred_x, y_true_x = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_per_label_test = calculate_acc_for_labels(all_labels = y_test,\n",
    "                                                     correct_labels = y_pred_o,\n",
    "                                                     num_classes = 10,\n",
    "                                                     labels = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_per_label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Problematic Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underfit_labels = get_underfit_labels(acc = accuracies_per_label_train,\n",
    "                                      num_classes = 10,\n",
    "                                      threshold = theta,\n",
    "                                      labels = []) \n",
    "\n",
    "print(underfit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_faultiest_label(underfit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_labels = get_overfit_labels(train_acc = accuracies_per_label_train,\n",
    "                                    test_acc = accuracies_per_label_test,\n",
    "                                    num_classes = 10,\n",
    "                                    threshold = gamma,\n",
    "                                    labels = [])\n",
    "\n",
    "print(overfit_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, heatmaps = get_heatmaps(correct_data = x_test_o,\n",
    "                                correct_labels = y_pred_o,\n",
    "                                misclassified_data = x_test_x, \n",
    "                                misclassified_labels = y_pred_x, \n",
    "                                misclassified_correct_labels = y_true_x, \n",
    "                                num_classes = 10,\n",
    "                                labels = [], \n",
    "                                type = 'hci')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Next Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_X, next_y, x_bug_fixes, y_bug_fixes = select_next_inputs(bug_fix_data = x_bug_fixes,\n",
    "                                                              bug_fix_labels = y_bug_fixes,\n",
    "                                                              heatmaps = heatmaps,\n",
    "                                                              target_label = 1,\n",
    "                                                              batch_size = batch_size,\n",
    "                                                              ratio = alpha,\n",
    "                                                              for_underfitting=True,\n",
    "                                                              distance_metric='dot')\n",
    "# check out an example of a desirable target\n",
    "print(next_y[0])\n",
    "visualize_array(next_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted Label Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Train model on all training data and evaluate performance on test data. \n",
    "\n",
    "\n",
    "1. Starting with underfitting first, select the target layer that enters a saturation point. \n",
    "2. Use the predictions of the target layer, generate heatmaps for each label.\n",
    "3. Calculate the per-label accuracy.\n",
    "4. Select the most faulty label for retraining (break if none). \n",
    "5. Generate a batch tailored to improving performance on that label.\n",
    "6. Train on this new batch\n",
    "7. Evaluate performance\n",
    "8. Return to 1 and repeat until there are no more faulty underfitting labels\n",
    "\n",
    "\n",
    "9. Select the most faulty overfitting label\n",
    "10. Use the predictions of the target layer, generate heatmaps for each label.\n",
    "11. Calculate the per-label accuracy.\n",
    "12. Select the most faulty label for retraining (break if none). \n",
    "13. Generate a batch tailored to improving performance on that label.\n",
    "14. Train on this new batch\n",
    "15. Evaluate performance\n",
    "16. Return to 1 and repeat until there are no more faulty underfitting labels\n",
    "\n",
    "\n",
    "17. Check if there are anymore underfitting labels, if so, return to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 5\n",
    "\n",
    "distance_metrics = ['dot', 'cosine', 'manhattan', 'euclidean', 'minkowski', 'earthmover', 'chebyshev', 'canberra', 'braycurtis']\n",
    "\n",
    "for distance_metric in distance_metrics:\n",
    "    \n",
    "    print('#####################################################################')\n",
    "    print('Testing: {} similarity'.format(distance_metric))\n",
    "    print('#####################################################################')\n",
    "    \n",
    "    # download MNIST\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    # split into test and train sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # normalize to [0,1] by dividing by the max value\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    # further split x_train and y_train into new training and bug fixing sets (50/50)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_bug_fixes, y_train, y_bug_fixes = train_test_split(x_train, y_train, test_size=0.5, random_state=123)\n",
    "\n",
    "    print('Training data shape: ', x_train.shape)\n",
    "    print('Training labels shape: ', y_train.shape)\n",
    "\n",
    "    print('Bug Fixing data shape: ', x_bug_fixes.shape)\n",
    "    print('Bug Fixing labels shape: ', y_bug_fixes.shape)\n",
    "\n",
    "    print('Test data shape: ', x_test.shape)\n",
    "    print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "    # create model layers\n",
    "    model = k.models.Sequential([\n",
    "      # flatten into a single vector\n",
    "      k.layers.Flatten(input_shape=(28, 28)),\n",
    "      # first layer\n",
    "      k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # second layer\n",
    "      k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # third layer\n",
    "      #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # fourth layer\n",
    "      #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # output layer\n",
    "      k.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # compile with optimizer, loss, and metrics\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit\n",
    "    model.fit(x_train, y_train, epochs=epochs)\n",
    "\n",
    "    # predict test (to get distributions)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Initial Test Loss: {}, Initial Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "    control_model = replicate_model(model)\n",
    "\n",
    "    control_model.compile(optimizer='adam',\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "\n",
    "        # control model with no specialized batch selection\n",
    "        control_batch_x, control_batch_y = x_bug_fixes[:batch_size], y_bug_fixes[:batch_size]\n",
    "        control_model.fit(control_batch_x, control_batch_y, epochs=epochs, verbose=0)\n",
    "\n",
    "        # identify target layer\n",
    "        print('Identifying target layer...')\n",
    "        target_layer, cache = Forward_Layer_Select(model, \n",
    "                                                   x_train, \n",
    "                                                   y_train, \n",
    "                                                   x_test, \n",
    "                                                   y_test, \n",
    "                                                   epochs, \n",
    "                                                   similarity_threshold, \n",
    "                                                   verbose=False)\n",
    "\n",
    "        feature_models, accuracies, bhattacharyyas, layer_pred = cache\n",
    "\n",
    "        # breakout eval sets\n",
    "        out = get_eval_datasets(data = x_test, \n",
    "                                labels = y_test, \n",
    "                                predictions = layer_pred)\n",
    "\n",
    "        data_correct, labels_correct, data_incorrect, labels_incorrect, labels_corrected = out\n",
    "\n",
    "        # generate heatmaps\n",
    "        labels, heatmaps = get_heatmaps(correct_data = data_correct,\n",
    "                                        correct_labels = labels_correct,\n",
    "                                        misclassified_data = data_incorrect, \n",
    "                                        misclassified_labels = labels_incorrect, \n",
    "                                        misclassified_correct_labels = labels_corrected, \n",
    "                                        num_classes = 10,\n",
    "                                        labels = [], \n",
    "                                        type = 'hci')\n",
    "\n",
    "        # identify buggy labels\n",
    "        accuracies_per_label_target = calculate_acc_for_labels(all_labels = y_test,\n",
    "                                                               correct_labels = labels_correct,\n",
    "                                                               num_classes = 10,\n",
    "                                                               labels = [])\n",
    "\n",
    "        underfit_labels = get_underfit_labels(acc = accuracies_per_label_target,\n",
    "                                              num_classes = 10,\n",
    "                                              threshold = theta,\n",
    "                                              labels = []) \n",
    "\n",
    "\n",
    "        # select the most faulty underfitting label\n",
    "        if len(underfit_labels) > 0:\n",
    "            faultiest_label = get_faultiest_label(underfit_labels)\n",
    "            print('Creating a batch for faultiest label: {}. There are {} faulty labels in total...'.format(faultiest_label, \n",
    "                                                                                                           len(underfit_labels)))\n",
    "            print('Faulty labels: ', underfit_labels)\n",
    "        else:\n",
    "            print('MODE retraining complete!')\n",
    "            break\n",
    "\n",
    "        # generate a batch tailored to improving performance on that label\n",
    "        next_X, next_y, x_bug_fixes, y_bug_fixes = select_next_inputs(bug_fix_data = x_bug_fixes,\n",
    "                                                                      bug_fix_labels = y_bug_fixes,\n",
    "                                                                      heatmaps = heatmaps,\n",
    "                                                                      target_label = faultiest_label,\n",
    "                                                                      batch_size = batch_size,\n",
    "                                                                      ratio = alpha,\n",
    "                                                                      for_underfitting = True,\n",
    "                                                                      distance_metric = distance_metric)\n",
    "\n",
    "        # train on this new batch\n",
    "        model.fit(next_X, next_y, epochs=epochs, verbose=1)\n",
    "\n",
    "        # evaluate performance\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test Loss: {}, Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "        # repeat until there are no more faulty underfitting labels\n",
    "        i += 1\n",
    "\n",
    "        print('{} iterations left...\\n'.format(max_iter - i))\n",
    "\n",
    "    print('Control model performance to beat:')  \n",
    "    control_loss, control_acc = control_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Control Test Loss: {}, Control Test Accuracy: {}'.format(control_loss, control_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 5\n",
    "\n",
    "distance_metrics = ['dot', 'cosine', 'manhattan', 'euclidean', 'minkowski', 'earthmover', 'chebyshev', 'canberra', 'braycurtis']\n",
    "\n",
    "for distance_metric in distance_metrics:\n",
    "    \n",
    "    print('#####################################################################')\n",
    "    print('Testing: {} similarity'.format(distance_metric))\n",
    "    print('#####################################################################')\n",
    "    \n",
    "    # download MNIST\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    # split into test and train sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # normalize to [0,1] by dividing by the max value\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    # further split x_train and y_train into new training and bug fixing sets (50/50)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_bug_fixes, y_train, y_bug_fixes = train_test_split(x_train, y_train, test_size=0.5, random_state=123)\n",
    "\n",
    "    print('Training data shape: ', x_train.shape)\n",
    "    print('Training labels shape: ', y_train.shape)\n",
    "\n",
    "    print('Bug Fixing data shape: ', x_bug_fixes.shape)\n",
    "    print('Bug Fixing labels shape: ', y_bug_fixes.shape)\n",
    "\n",
    "    print('Test data shape: ', x_test.shape)\n",
    "    print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "    # create model layers\n",
    "    model = k.models.Sequential([\n",
    "      # flatten into a single vector\n",
    "      k.layers.Flatten(input_shape=(28, 28)),\n",
    "      # first layer\n",
    "      k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # second layer\n",
    "      k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # third layer\n",
    "      #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # fourth layer\n",
    "      #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "      #k.layers.Dropout(0.2),\n",
    "      # output layer\n",
    "      k.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # compile with optimizer, loss, and metrics\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit\n",
    "    model.fit(x_train, y_train, epochs=epochs)\n",
    "\n",
    "    # predict test (to get distributions)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Initial Test Loss: {}, Initial Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "    control_model = replicate_model(model)\n",
    "\n",
    "    control_model.compile(optimizer='adam',\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "\n",
    "        # control model with no specialized batch selection\n",
    "        control_batch_x, control_batch_y = x_bug_fixes[:batch_size], y_bug_fixes[:batch_size]\n",
    "        control_model.fit(control_batch_x, control_batch_y, epochs=epochs, verbose=0)\n",
    "\n",
    "        # breakout eval sets\n",
    "        out = get_eval_datasets(data = x_test, \n",
    "                                labels = y_test, \n",
    "                                predictions = y_pred)\n",
    "\n",
    "        data_correct, labels_correct, data_incorrect, labels_incorrect, labels_corrected = out\n",
    "\n",
    "        # generate heatmaps\n",
    "        labels, heatmaps = get_heatmaps(correct_data = data_correct,\n",
    "                                        correct_labels = labels_correct,\n",
    "                                        misclassified_data = data_incorrect, \n",
    "                                        misclassified_labels = labels_incorrect, \n",
    "                                        misclassified_correct_labels = labels_corrected, \n",
    "                                        num_classes = 10,\n",
    "                                        labels = [], \n",
    "                                        type = 'hci')\n",
    "\n",
    "        # identify buggy labels\n",
    "        accuracies_per_label_target = calculate_acc_for_labels(all_labels = y_test,\n",
    "                                                               correct_labels = labels_correct,\n",
    "                                                               num_classes = 10,\n",
    "                                                               labels = [])\n",
    "\n",
    "        underfit_labels = get_underfit_labels(acc = accuracies_per_label_target,\n",
    "                                              num_classes = 10,\n",
    "                                              threshold = theta,\n",
    "                                              labels = []) \n",
    "\n",
    "\n",
    "        # select the most faulty underfitting label\n",
    "        if len(underfit_labels) > 0:\n",
    "            faultiest_label = get_faultiest_label(underfit_labels)\n",
    "            print('Creating a batch for faultiest label: {}. There are {} faulty labels in total...'.format(faultiest_label, \n",
    "                                                                                                           len(underfit_labels)))\n",
    "            print('Faulty labels: ', underfit_labels)\n",
    "        else:\n",
    "            print('MODE retraining complete!')\n",
    "            break\n",
    "\n",
    "        # generate a batch tailored to improving performance on that label\n",
    "        next_X, next_y, x_bug_fixes, y_bug_fixes = select_next_inputs(bug_fix_data = x_bug_fixes,\n",
    "                                                                      bug_fix_labels = y_bug_fixes,\n",
    "                                                                      heatmaps = heatmaps,\n",
    "                                                                      target_label = faultiest_label,\n",
    "                                                                      batch_size = batch_size,\n",
    "                                                                      ratio = alpha,\n",
    "                                                                      for_underfitting=True,\n",
    "                                                                      distance_metric=distance_metric)\n",
    "\n",
    "        # train on this new batch\n",
    "        model.fit(next_X, next_y, epochs=epochs, verbose=1)\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # evaluate performance\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test Loss: {}, Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "        # repeat until there are no more faulty underfitting labels\n",
    "        i += 1\n",
    "\n",
    "        print('{} iterations left...\\n'.format(max_iter - i))\n",
    "\n",
    "    print('Control model performance to beat:')  \n",
    "    control_loss, control_acc = control_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Control Test Loss: {}, Control Test Accuracy: {}'.format(control_loss, control_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "max_iter = 5\n",
    "\n",
    "# download MNIST\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# split into test and train sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize to [0,1] by dividing by the max value\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# further split x_train and y_train into new training and bug fixing sets (50/50)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_bug_fixes, y_train, y_bug_fixes = train_test_split(x_train, y_train, test_size=0.5, random_state=123)\n",
    "\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "\n",
    "print('Bug Fixing data shape: ', x_bug_fixes.shape)\n",
    "print('Bug Fixing labels shape: ', y_bug_fixes.shape)\n",
    "\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# create model layers\n",
    "model = k.models.Sequential([\n",
    "  # flatten into a single vector\n",
    "  k.layers.Flatten(input_shape=(28, 28)),\n",
    "  # first layer\n",
    "  k.layers.Dense(28, activation=tf.nn.relu),\n",
    "  #k.layers.Dropout(0.2),\n",
    "  # second layer\n",
    "  k.layers.Dense(28, activation=tf.nn.relu),\n",
    "  #k.layers.Dropout(0.2),\n",
    "  # third layer\n",
    "  #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "  #k.layers.Dropout(0.2),\n",
    "  # fourth layer\n",
    "  #k.layers.Dense(28, activation=tf.nn.relu),\n",
    "  #k.layers.Dropout(0.2),\n",
    "  # output layer\n",
    "  k.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# compile with optimizer, loss, and metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit\n",
    "model.fit(x_train, y_train, epochs=epochs)\n",
    "\n",
    "# predict test (to get distributions)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Initial Test Loss: {}, Initial Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "control_model = replicate_model(model)\n",
    "\n",
    "control_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "i = 0\n",
    "while i < max_iter:\n",
    "\n",
    "    # control model with no specialized batch selection\n",
    "    control_batch_x, control_batch_y = x_bug_fixes[:batch_size], y_bug_fixes[:batch_size]\n",
    "    control_model.fit(control_batch_x, control_batch_y, epochs=epochs, verbose=0)\n",
    "\n",
    "    # identify target layer\n",
    "    print('Identifying target layer...')\n",
    "    target_layer, cache = Forward_Layer_Select(model, \n",
    "                                               x_train, \n",
    "                                               y_train, \n",
    "                                               x_test, \n",
    "                                               y_test, \n",
    "                                               epochs, \n",
    "                                               similarity_threshold, \n",
    "                                               verbose=False)\n",
    "\n",
    "    feature_models, accuracies, bhattacharyyas, layer_pred = cache\n",
    "\n",
    "    # breakout eval sets\n",
    "    out = get_eval_datasets(data = x_test, \n",
    "                            labels = y_test, \n",
    "                            predictions = layer_pred)\n",
    "\n",
    "    data_correct, labels_correct, data_incorrect, labels_incorrect, labels_corrected = out\n",
    "\n",
    "    # generate heatmaps\n",
    "    labels, heatmaps = get_heatmaps(correct_data = data_correct,\n",
    "                                    correct_labels = labels_correct,\n",
    "                                    misclassified_data = data_incorrect, \n",
    "                                    misclassified_labels = labels_incorrect, \n",
    "                                    misclassified_correct_labels = labels_corrected, \n",
    "                                    num_classes = 10,\n",
    "                                    labels = [], \n",
    "                                    type = 'hci')\n",
    "\n",
    "    # identify buggy labels\n",
    "    accuracies_per_label_target = calculate_acc_for_labels(all_labels = y_test,\n",
    "                                                           correct_labels = labels_correct,\n",
    "                                                           num_classes = 10,\n",
    "                                                           labels = [])\n",
    "\n",
    "    underfit_labels = get_underfit_labels(acc = accuracies_per_label_target,\n",
    "                                          num_classes = 10,\n",
    "                                          threshold = theta,\n",
    "                                          labels = []) \n",
    "\n",
    "\n",
    "    # select the most faulty underfitting label\n",
    "    if len(underfit_labels) > 0:\n",
    "        faultiest_label = get_faultiest_label(underfit_labels)\n",
    "        print('Creating a batch for faultiest label: {}. There are {} faulty labels in total...'.format(faultiest_label, \n",
    "                                                                                                       len(underfit_labels)))\n",
    "        print('Faulty labels: ', underfit_labels)\n",
    "    else:\n",
    "        print('MODE retraining complete!')\n",
    "        break\n",
    "\n",
    "    # generate a batch tailored to improving performance on that label\n",
    "    next_X, next_y, x_bug_fixes, y_bug_fixes = select_next_inputs(bug_fix_data = x_bug_fixes,\n",
    "                                                                  bug_fix_labels = y_bug_fixes,\n",
    "                                                                  heatmaps = heatmaps,\n",
    "                                                                  target_label = faultiest_label,\n",
    "                                                                  batch_size = batch_size,\n",
    "                                                                  ratio = alpha,\n",
    "                                                                  for_underfitting = True,\n",
    "                                                                  distance_metric = 'dot')\n",
    "\n",
    "    # train on this new batch\n",
    "    model.fit(next_X, next_y, epochs=epochs, verbose=1)\n",
    "\n",
    "    # evaluate performance\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test Loss: {}, Test Accuracy: {}'.format(test_loss, test_acc))\n",
    "\n",
    "    # repeat until there are no more faulty underfitting labels\n",
    "    i += 1\n",
    "\n",
    "    print('{} iterations left...\\n'.format(max_iter - i))\n",
    "\n",
    "print('Control model performance to beat:')  \n",
    "control_loss, control_acc = control_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Control Test Loss: {}, Control Test Accuracy: {}'.format(control_loss, control_acc))\n",
    "\n",
    "print('That took {} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_misclassifications(misclassified_data = x_test_x, \n",
    "                          misclassified_labels = y_pred_x, \n",
    "                          misclassified_correct_labels = y_true_x, \n",
    "                          num_samples=1, \n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_heatmaps_for_correct_prediction(correct_data = x_test_o,\n",
    "                                    correct_labels = y_pred_o,\n",
    "                                    num_classes = 10,\n",
    "                                    labels = [],\n",
    "                                    cmap = 'seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_heatmaps_for_false_positives(misclassified_data = x_test_x, \n",
    "                                 misclassified_correct_labels = y_true_x, \n",
    "                                 num_classes = 10,\n",
    "                                 cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_heatmaps_for_false_negatives(misclassified_data = x_test_x, \n",
    "                                 misclassified_labels = y_pred_x, \n",
    "                                 num_classes = 10,\n",
    "                                 cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHCI_i_k(correct_data = x_test_o,\n",
    "         correct_labels = y_pred_o,\n",
    "         first_label = 1, \n",
    "         second_label = 2,\n",
    "         cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHMI_i(correct_data = x_test_o,\n",
    "       correct_labels = y_pred_o,\n",
    "       misclassified_data = x_test_x,\n",
    "       misclassified_correct_labels = y_true_x, \n",
    "       num_classes = 10,\n",
    "       cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHWI_i(correct_data = x_test_o,\n",
    "       correct_labels = y_pred_o,\n",
    "       misclassified_data = x_test_x,\n",
    "       misclassified_labels = y_pred_x, \n",
    "       num_classes = 10,\n",
    "       cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='minkowski',\n",
    "                       minkowski_power=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='earthmover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='chebyshev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='canberra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_most_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                       bug_fix_labels = y_bug_fixes,\n",
    "                       labels = labels,\n",
    "                       heatmaps = heatmaps,\n",
    "                       distance_metric='braycurtis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance_metric in distance_metrics:\n",
    "\n",
    "    viz_most_similar(bug_fix_data = x_bug_fixes,\n",
    "                     bug_fix_labels = y_bug_fixes,\n",
    "                     labels = labels,\n",
    "                     heatmaps = heatmaps,\n",
    "                     distance_metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance_metric in distance_metrics:\n",
    "\n",
    "    viz_least_similar(bug_fix_data = x_bug_fixes,\n",
    "                     bug_fix_labels = y_bug_fixes,\n",
    "                     labels = labels,\n",
    "                     heatmaps = heatmaps,\n",
    "                     distance_metric=distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
