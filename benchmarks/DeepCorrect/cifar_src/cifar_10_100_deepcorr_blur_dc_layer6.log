nohup: ignoring input
Using Theano backend.
0.5
50
compiled model successfully
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input (InputLayer)               (None, 3, 32, 32)     0                                            
____________________________________________________________________________________________________
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 34, 34)     0           input[0][0]                      
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 96, 32, 32)    2688        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
lambda_2 (Lambda)                (None, 50, 32, 32)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 50, 32, 32)    200         lambda_2[0][0]                   
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 32, 32)    3264        batchnormalization_2[0][0]       
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 64, 32, 32)    256         convolution2d_2[0][0]            
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 64, 32, 32)    0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
zeropadding2d_2 (ZeroPadding2D)  (None, 64, 34, 34)    0           activation_1[0][0]               
____________________________________________________________________________________________________
atrousconvolution2d_1 (AtrousCon (None, 64, 32, 32)    36928       zeropadding2d_2[0][0]            
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 64, 32, 32)    256         atrousconvolution2d_1[0][0]      
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 64, 32, 32)    0           batchnormalization_4[0][0]       
____________________________________________________________________________________________________
zeropadding2d_3 (ZeroPadding2D)  (None, 64, 34, 34)    0           activation_2[0][0]               
____________________________________________________________________________________________________
atrousconvolution2d_2 (AtrousCon (None, 64, 32, 32)    36928       zeropadding2d_3[0][0]            
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 64, 32, 32)    256         atrousconvolution2d_2[0][0]      
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 64, 32, 32)    0           batchnormalization_5[0][0]       
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 50, 32, 32)    3250        activation_3[0][0]               
____________________________________________________________________________________________________
merge_1 (Merge)                  (None, 50, 32, 32)    0           convolution2d_3[0][0]            
                                                                   lambda_2[0][0]                   
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 46, 32, 32)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 50, 32, 32)    200         merge_1[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 46, 32, 32)    184         lambda_1[0][0]                   
____________________________________________________________________________________________________
merge_2 (Merge)                  (None, 96, 32, 32)    0           batchnormalization_6[0][0]       
                                                                   batchnormalization_1[0][0]       
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 96, 32, 32)    0           merge_2[0][0]                    
____________________________________________________________________________________________________
zeropadding2d_4 (ZeroPadding2D)  (None, 96, 34, 34)    0           activation_4[0][0]               
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 96, 32, 32)    83040       zeropadding2d_4[0][0]            
____________________________________________________________________________________________________
lambda_4 (Lambda)                (None, 50, 32, 32)    0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
batchnormalization_8 (BatchNorma (None, 50, 32, 32)    200         lambda_4[0][0]                   
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 64, 32, 32)    3264        batchnormalization_8[0][0]       
____________________________________________________________________________________________________
batchnormalization_9 (BatchNorma (None, 64, 32, 32)    256         convolution2d_5[0][0]            
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 64, 32, 32)    0           batchnormalization_9[0][0]       
____________________________________________________________________________________________________
zeropadding2d_5 (ZeroPadding2D)  (None, 64, 34, 34)    0           activation_5[0][0]               
____________________________________________________________________________________________________
atrousconvolution2d_3 (AtrousCon (None, 64, 32, 32)    36928       zeropadding2d_5[0][0]            
____________________________________________________________________________________________________
batchnormalization_10 (BatchNorm (None, 64, 32, 32)    256         atrousconvolution2d_3[0][0]      
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 64, 32, 32)    0           batchnormalization_10[0][0]      
____________________________________________________________________________________________________
zeropadding2d_6 (ZeroPadding2D)  (None, 64, 34, 34)    0           activation_6[0][0]               
____________________________________________________________________________________________________
atrousconvolution2d_4 (AtrousCon (None, 64, 32, 32)    36928       zeropadding2d_6[0][0]            
____________________________________________________________________________________________________
batchnormalization_11 (BatchNorm (None, 64, 32, 32)    256         atrousconvolution2d_4[0][0]      
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 64, 32, 32)    0           batchnormalization_11[0][0]      
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 50, 32, 32)    3250        activation_7[0][0]               
____________________________________________________________________________________________________
merge_3 (Merge)                  (None, 50, 32, 32)    0           convolution2d_6[0][0]            
                                                                   lambda_4[0][0]                   
____________________________________________________________________________________________________
lambda_3 (Lambda)                (None, 46, 32, 32)    0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
batchnormalization_12 (BatchNorm (None, 50, 32, 32)    200         merge_3[0][0]                    
____________________________________________________________________________________________________
batchnormalization_7 (BatchNorma (None, 46, 32, 32)    184         lambda_3[0][0]                   
____________________________________________________________________________________________________
merge_4 (Merge)                  (None, 96, 32, 32)    0           batchnormalization_12[0][0]      
                                                                   batchnormalization_7[0][0]       
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 96, 32, 32)    0           merge_4[0][0]                    
____________________________________________________________________________________________________
zeropadding2d_7 (ZeroPadding2D)  (None, 96, 34, 34)    0           activation_8[0][0]               
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 96, 16, 16)    83040       zeropadding2d_7[0][0]            
____________________________________________________________________________________________________
lambda_6 (Lambda)                (None, 50, 16, 16)    0           convolution2d_7[0][0]            
____________________________________________________________________________________________________
batchnormalization_14 (BatchNorm (None, 50, 16, 16)    200         lambda_6[0][0]                   
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 64, 16, 16)    3264        batchnormalization_14[0][0]      
____________________________________________________________________________________________________
batchnormalization_15 (BatchNorm (None, 64, 16, 16)    256         convolution2d_8[0][0]            
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 64, 16, 16)    0           batchnormalization_15[0][0]      
____________________________________________________________________________________________________
zeropadding2d_8 (ZeroPadding2D)  (None, 64, 18, 18)    0           activation_9[0][0]               
____________________________________________________________________________________________________
atrousconvolution2d_5 (AtrousCon (None, 64, 16, 16)    36928       zeropadding2d_8[0][0]            
____________________________________________________________________________________________________
batchnormalization_16 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_5[0][0]      
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 64, 16, 16)    0           batchnormalization_16[0][0]      
____________________________________________________________________________________________________
zeropadding2d_9 (ZeroPadding2D)  (None, 64, 18, 18)    0           activation_10[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_6 (AtrousCon (None, 64, 16, 16)    36928       zeropadding2d_9[0][0]            
____________________________________________________________________________________________________
batchnormalization_17 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_6[0][0]      
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 64, 16, 16)    0           batchnormalization_17[0][0]      
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 50, 16, 16)    3250        activation_11[0][0]              
____________________________________________________________________________________________________
merge_5 (Merge)                  (None, 50, 16, 16)    0           convolution2d_9[0][0]            
                                                                   lambda_6[0][0]                   
____________________________________________________________________________________________________
lambda_5 (Lambda)                (None, 46, 16, 16)    0           convolution2d_7[0][0]            
____________________________________________________________________________________________________
batchnormalization_18 (BatchNorm (None, 50, 16, 16)    200         merge_5[0][0]                    
____________________________________________________________________________________________________
batchnormalization_13 (BatchNorm (None, 46, 16, 16)    184         lambda_5[0][0]                   
____________________________________________________________________________________________________
merge_6 (Merge)                  (None, 96, 16, 16)    0           batchnormalization_18[0][0]      
                                                                   batchnormalization_13[0][0]      
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 96, 16, 16)    0           merge_6[0][0]                    
____________________________________________________________________________________________________
zeropadding2d_10 (ZeroPadding2D) (None, 96, 18, 18)    0           activation_12[0][0]              
____________________________________________________________________________________________________
convolution2d_10 (Convolution2D) (None, 192, 16, 16)   166080      zeropadding2d_10[0][0]           
____________________________________________________________________________________________________
lambda_8 (Lambda)                (None, 100, 16, 16)   0           convolution2d_10[0][0]           
____________________________________________________________________________________________________
batchnormalization_20 (BatchNorm (None, 100, 16, 16)   400         lambda_8[0][0]                   
____________________________________________________________________________________________________
convolution2d_11 (Convolution2D) (None, 64, 16, 16)    6464        batchnormalization_20[0][0]      
____________________________________________________________________________________________________
batchnormalization_21 (BatchNorm (None, 64, 16, 16)    256         convolution2d_11[0][0]           
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 64, 16, 16)    0           batchnormalization_21[0][0]      
____________________________________________________________________________________________________
zeropadding2d_11 (ZeroPadding2D) (None, 64, 18, 18)    0           activation_13[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_7 (AtrousCon (None, 64, 16, 16)    36928       zeropadding2d_11[0][0]           
____________________________________________________________________________________________________
batchnormalization_22 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_7[0][0]      
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 64, 16, 16)    0           batchnormalization_22[0][0]      
____________________________________________________________________________________________________
zeropadding2d_12 (ZeroPadding2D) (None, 64, 18, 18)    0           activation_14[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_8 (AtrousCon (None, 64, 16, 16)    36928       zeropadding2d_12[0][0]           
____________________________________________________________________________________________________
batchnormalization_23 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_8[0][0]      
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 64, 16, 16)    0           batchnormalization_23[0][0]      
____________________________________________________________________________________________________
convolution2d_12 (Convolution2D) (None, 100, 16, 16)   6500        activation_15[0][0]              
____________________________________________________________________________________________________
merge_7 (Merge)                  (None, 100, 16, 16)   0           convolution2d_12[0][0]           
                                                                   lambda_8[0][0]                   
____________________________________________________________________________________________________
lambda_7 (Lambda)                (None, 92, 16, 16)    0           convolution2d_10[0][0]           
____________________________________________________________________________________________________
batchnormalization_24 (BatchNorm (None, 100, 16, 16)   400         merge_7[0][0]                    
____________________________________________________________________________________________________
batchnormalization_19 (BatchNorm (None, 92, 16, 16)    368         lambda_7[0][0]                   
____________________________________________________________________________________________________
merge_8 (Merge)                  (None, 192, 16, 16)   0           batchnormalization_24[0][0]      
                                                                   batchnormalization_19[0][0]      
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 192, 16, 16)   0           merge_8[0][0]                    
____________________________________________________________________________________________________
zeropadding2d_13 (ZeroPadding2D) (None, 192, 18, 18)   0           activation_16[0][0]              
____________________________________________________________________________________________________
convolution2d_13 (Convolution2D) (None, 192, 16, 16)   331968      zeropadding2d_13[0][0]           
____________________________________________________________________________________________________
lambda_10 (Lambda)               (None, 100, 16, 16)   0           convolution2d_13[0][0]           
____________________________________________________________________________________________________
batchnormalization_26 (BatchNorm (None, 100, 16, 16)   400         lambda_10[0][0]                  
____________________________________________________________________________________________________
convolution2d_14 (Convolution2D) (None, 64, 16, 16)    6464        batchnormalization_26[0][0]      
____________________________________________________________________________________________________
batchnormalization_27 (BatchNorm (None, 64, 16, 16)    256         convolution2d_14[0][0]           
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 64, 16, 16)    0           batchnormalization_27[0][0]      
____________________________________________________________________________________________________
zeropadding2d_14 (ZeroPadding2D) (None, 64, 18, 18)    0           activation_17[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_9 (AtrousCon (None, 64, 16, 16)    36928       zeropadding2d_14[0][0]           
____________________________________________________________________________________________________
batchnormalization_28 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_9[0][0]      
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 64, 16, 16)    0           batchnormalization_28[0][0]      
____________________________________________________________________________________________________
zeropadding2d_15 (ZeroPadding2D) (None, 64, 18, 18)    0           activation_18[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_10 (AtrousCo (None, 64, 16, 16)    36928       zeropadding2d_15[0][0]           
____________________________________________________________________________________________________
batchnormalization_29 (BatchNorm (None, 64, 16, 16)    256         atrousconvolution2d_10[0][0]     
____________________________________________________________________________________________________
activation_19 (Activation)       (None, 64, 16, 16)    0           batchnormalization_29[0][0]      
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 100, 16, 16)   6500        activation_19[0][0]              
____________________________________________________________________________________________________
merge_9 (Merge)                  (None, 100, 16, 16)   0           convolution2d_15[0][0]           
                                                                   lambda_10[0][0]                  
____________________________________________________________________________________________________
lambda_9 (Lambda)                (None, 92, 16, 16)    0           convolution2d_13[0][0]           
____________________________________________________________________________________________________
batchnormalization_30 (BatchNorm (None, 100, 16, 16)   400         merge_9[0][0]                    
____________________________________________________________________________________________________
batchnormalization_25 (BatchNorm (None, 92, 16, 16)    368         lambda_9[0][0]                   
____________________________________________________________________________________________________
merge_10 (Merge)                 (None, 192, 16, 16)   0           batchnormalization_30[0][0]      
                                                                   batchnormalization_25[0][0]      
____________________________________________________________________________________________________
activation_20 (Activation)       (None, 192, 16, 16)   0           merge_10[0][0]                   
____________________________________________________________________________________________________
zeropadding2d_16 (ZeroPadding2D) (None, 192, 18, 18)   0           activation_20[0][0]              
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 192, 8, 8)     331968      zeropadding2d_16[0][0]           
____________________________________________________________________________________________________
lambda_12 (Lambda)               (None, 100, 8, 8)     0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
batchnormalization_32 (BatchNorm (None, 100, 8, 8)     400         lambda_12[0][0]                  
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 64, 8, 8)      6464        batchnormalization_32[0][0]      
____________________________________________________________________________________________________
batchnormalization_33 (BatchNorm (None, 64, 8, 8)      256         convolution2d_17[0][0]           
____________________________________________________________________________________________________
activation_21 (Activation)       (None, 64, 8, 8)      0           batchnormalization_33[0][0]      
____________________________________________________________________________________________________
zeropadding2d_17 (ZeroPadding2D) (None, 64, 10, 10)    0           activation_21[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_11 (AtrousCo (None, 64, 8, 8)      36928       zeropadding2d_17[0][0]           
____________________________________________________________________________________________________
batchnormalization_34 (BatchNorm (None, 64, 8, 8)      256         atrousconvolution2d_11[0][0]     
____________________________________________________________________________________________________
activation_22 (Activation)       (None, 64, 8, 8)      0           batchnormalization_34[0][0]      
____________________________________________________________________________________________________
zeropadding2d_18 (ZeroPadding2D) (None, 64, 10, 10)    0           activation_22[0][0]              
____________________________________________________________________________________________________
atrousconvolution2d_12 (AtrousCo (None, 64, 8, 8)      36928       zeropadding2d_18[0][0]           
____________________________________________________________________________________________________
batchnormalization_35 (BatchNorm (None, 64, 8, 8)      256         atrousconvolution2d_12[0][0]     
____________________________________________________________________________________________________
activation_23 (Activation)       (None, 64, 8, 8)      0           batchnormalization_35[0][0]      
____________________________________________________________________________________________________
convolution2d_18 (Convolution2D) (None, 100, 8, 8)     6500        activation_23[0][0]              
____________________________________________________________________________________________________
merge_11 (Merge)                 (None, 100, 8, 8)     0           convolution2d_18[0][0]           
                                                                   lambda_12[0][0]                  
____________________________________________________________________________________________________
lambda_11 (Lambda)               (None, 92, 8, 8)      0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
batchnormalization_36 (BatchNorm (None, 100, 8, 8)     400         merge_11[0][0]                   
____________________________________________________________________________________________________
batchnormalization_31 (BatchNorm (None, 92, 8, 8)      368         lambda_11[0][0]                  
____________________________________________________________________________________________________
merge_12 (Merge)                 (None, 192, 8, 8)     0           batchnormalization_36[0][0]      
                                                                   batchnormalization_31[0][0]      
____________________________________________________________________________________________________
activation_24 (Activation)       (None, 192, 8, 8)     0           merge_12[0][0]                   
____________________________________________________________________________________________________
convolution2d_19 (Convolution2D) (None, 192, 6, 6)     331968      activation_24[0][0]              
____________________________________________________________________________________________________
batchnormalization_37 (BatchNorm (None, 192, 6, 6)     768         convolution2d_19[0][0]           
____________________________________________________________________________________________________
activation_25 (Activation)       (None, 192, 6, 6)     0           batchnormalization_37[0][0]      
____________________________________________________________________________________________________
convolution2d_20 (Convolution2D) (None, 192, 6, 6)     37056       activation_25[0][0]              
____________________________________________________________________________________________________
batchnormalization_38 (BatchNorm (None, 192, 6, 6)     768         convolution2d_20[0][0]           
____________________________________________________________________________________________________
activation_26 (Activation)       (None, 192, 6, 6)     0           batchnormalization_38[0][0]      
____________________________________________________________________________________________________
convolution2d_21 (Convolution2D) (None, 100, 6, 6)     19300       activation_26[0][0]              
____________________________________________________________________________________________________
batchnormalization_39 (BatchNorm (None, 100, 6, 6)     400         convolution2d_21[0][0]           
____________________________________________________________________________________________________
activation_27 (Activation)       (None, 100, 6, 6)     0           batchnormalization_39[0][0]      
____________________________________________________________________________________________________
averagepooling2d_1 (AveragePooli (None, 100, 1, 1)     0           activation_27[0][0]              
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 100)           0           averagepooling2d_1[0][0]         
____________________________________________________________________________________________________
output (Activation)              (None, 100)           0           flatten_1[0][0]                  
====================================================================================================
Total params: 1,900,478
Trainable params: 505,674
Non-trainable params: 1,394,804
____________________________________________________________________________________________________

 distortion type blur
Epoch : 
1
Learning rate : 0.00999999977648
Epoch 1/1
  250/90000 [..............................] - ETA: 12489s - loss: 5.8092 - acc: 0.0320  500/90000 [..............................] - ETA: 12183s - loss: 5.6958 - acc: 0.0520  750/90000 [..............................] - ETA: 12067s - loss: 5.5613 - acc: 0.0547 1000/90000 [..............................] - ETA: 11950s - loss: 5.5047 - acc: 0.0540 1250/90000 [..............................] - ETA: 11917s - loss: 5.4843 - acc: 0.0576 1500/90000 [..............................] - ETA: 11822s - loss: 5.4837 - acc: 0.0607 1750/90000 [..............................] - ETA: 11713s - loss: 5.4827 - acc: 0.0606 2000/90000 [..............................] - ETA: 11627s - loss: 5.4621 - acc: 0.0630 2250/90000 [..............................] - ETA: 11526s - loss: 5.4241 - acc: 0.0662 2500/90000 [..............................] - ETA: 11446s - loss: 5.3887 - acc: 0.0684 2750/90000 [..............................] - ETA: 11370s - loss: 5.3697 - acc: 0.0691 3000/90000 [>.............................] - ETA: 11310s - loss: 5.3374 - acc: 0.0710 3250/90000 [>.............................] - ETA: 11291s - loss: 5.3206 - acc: 0.0735 3500/90000 [>.............................] - ETA: 11262s - loss: 5.2933 - acc: 0.0774 3750/90000 [>.............................] - ETA: 11218s - loss: 5.2568 - acc: 0.0789 4000/90000 [>.............................] - ETA: 11199s - loss: 5.2357 - acc: 0.0802 4250/90000 [>.............................] - ETA: 11183s - loss: 5.2066 - acc: 0.0831 4500/90000 [>.............................] - ETA: 11180s - loss: 5.1887 - acc: 0.0844 4750/90000 [>.............................] - ETA: 11131s - loss: 5.1612 - acc: 0.0861 5000/90000 [>.............................] - ETA: 11089s - loss: 5.1400 - acc: 0.0896 5250/90000 [>.............................] - ETA: 11055s - loss: 5.1121 - acc: 0.0918 5500/90000 [>.............................] - ETA: 11025s - loss: 5.0904 - acc: 0.0933 5750/90000 [>.............................] - ETA: 10966s - loss: 5.0723 - acc: 0.0958 6000/90000 [=>............................] - ETA: 10925s - loss: 5.0401 - acc: 0.1003 6250/90000 [=>............................] - ETA: 10896s - loss: 5.0288 - acc: 0.1006 6500/90000 [=>............................] - ETA: 10861s - loss: 5.0130 - acc: 0.1023 6750/90000 [=>............................] - ETA: 10819s - loss: 4.9977 - acc: 0.1040 7000/90000 [=>............................] - ETA: 10778s - loss: 4.9770 - acc: 0.1066 7250/90000 [=>............................] - ETA: 10747s - loss: 4.9568 - acc: 0.1088 7500/90000 [=>............................] - ETA: 10707s - loss: 4.9327 - acc: 0.1124 7750/90000 [=>............................] - ETA: 10674s - loss: 4.9095 - acc: 0.1148 8000/90000 [=>............................] - ETA: 10646s - loss: 4.8843 - acc: 0.1181 8250/90000 [=>............................] - ETA: 10618s - loss: 4.8611 - acc: 0.1207 8500/90000 [=>............................] - ETA: 10583s - loss: 4.8319 - acc: 0.1242 8750/90000 [=>............................] - ETA: 10548s - loss: 4.8022 - acc: 0.1282 9000/90000 [==>...........................] - ETA: 10506s - loss: 4.7821 - acc: 0.1310 9250/90000 [==>...........................] - ETA: 10462s - loss: 4.7543 - acc: 0.1345 9500/90000 [==>...........................] - ETA: 10434s - loss: 4.7316 - acc: 0.1378 9750/90000 [==>...........................] - ETA: 10401s - loss: 4.7129 - acc: 0.140410000/90000 [==>...........................] - ETA: 10367s - loss: 4.6912 - acc: 0.142210250/90000 [==>...........................] - ETA: 10334s - loss: 4.6714 - acc: 0.144810500/90000 [==>...........................] - ETA: 10300s - loss: 4.6481 - acc: 0.148410750/90000 [==>...........................] - ETA: 10268s - loss: 4.6263 - acc: 0.151811000/90000 [==>...........................] - ETA: 10235s - loss: 4.6051 - acc: 0.155311250/90000 [==>...........................] - ETA: 10193s - loss: 4.5838 - acc: 0.158611500/90000 [==>...........................] - ETA: 10150s - loss: 4.5678 - acc: 0.161311750/90000 [==>...........................] - ETA: 10114s - loss: 4.5486 - acc: 0.164012000/90000 [===>..........................] - ETA: 10074s - loss: 4.5295 - acc: 0.166312250/90000 [===>..........................] - ETA: 10039s - loss: 4.5082 - acc: 0.169712500/90000 [===>..........................] - ETA: 10005s - loss: 4.4841 - acc: 0.173112750/90000 [===>..........................] - ETA: 9974s - loss: 4.4650 - acc: 0.1766 13000/90000 [===>..........................] - ETA: 9941s - loss: 4.4449 - acc: 0.179613250/90000 [===>..........................] - ETA: 9902s - loss: 4.4268 - acc: 0.181813500/90000 [===>..........................] - ETA: 9875s - loss: 4.4042 - acc: 0.185313750/90000 [===>..........................] - ETA: 9843s - loss: 4.3867 - acc: 0.188114000/90000 [===>..........................] - ETA: 9804s - loss: 4.3683 - acc: 0.190614250/90000 [===>..........................] - ETA: 9769s - loss: 4.3481 - acc: 0.193914500/90000 [===>..........................] - ETA: 9728s - loss: 4.3351 - acc: 0.195614750/90000 [===>..........................] - ETA: 9697s - loss: 4.3163 - acc: 0.197815000/90000 [====>.........................] - ETA: 9664s - loss: 4.2973 - acc: 0.200715250/90000 [====>.........................] - ETA: 9631s - loss: 4.2774 - acc: 0.203115500/90000 [====>.........................] - ETA: 9603s - loss: 4.2616 - acc: 0.205515750/90000 [====>.........................] - ETA: 9573s - loss: 4.2479 - acc: 0.207416000/90000 [====>.........................] - ETA: 9541s - loss: 4.2262 - acc: 0.210616250/90000 [====>.........................] - ETA: 9506s - loss: 4.2085 - acc: 0.212916500/90000 [====>.........................] - ETA: 9471s - loss: 4.1955 - acc: 0.214616750/90000 [====>.........................] - ETA: 9436s - loss: 4.1759 - acc: 0.217717000/90000 [====>.........................] - ETA: 9399s - loss: 4.1628 - acc: 0.219717250/90000 [====>.........................] - ETA: 9364s - loss: 4.1468 - acc: 0.221717500/90000 [====>.........................] - ETA: 9329s - loss: 4.1295 - acc: 0.224417750/90000 [====>.........................] - ETA: 9297s - loss: 4.1114 - acc: 0.227418000/90000 [=====>........................] - ETA: 9267s - loss: 4.0973 - acc: 0.229718250/90000 [=====>........................] - ETA: 9234s - loss: 4.0834 - acc: 0.231718500/90000 [=====>........................] - ETA: 9203s - loss: 4.0669 - acc: 0.234318750/90000 [=====>........................] - ETA: 9172s - loss: 4.0512 - acc: 0.236619000/90000 [=====>........................] - ETA: 9139s - loss: 4.0383 - acc: 0.238819250/90000 [=====>........................] - ETA: 9107s - loss: 4.0232 - acc: 0.240819500/90000 [=====>........................] - ETA: 9074s - loss: 4.0093 - acc: 0.243019750/90000 [=====>........................] - ETA: 9039s - loss: 3.9919 - acc: 0.245720000/90000 [=====>........................] - ETA: 9006s - loss: 3.9770 - acc: 0.248120250/90000 [=====>........................] - ETA: 8974s - loss: 3.9612 - acc: 0.250620500/90000 [=====>........................] - ETA: 8940s - loss: 3.9458 - acc: 0.253020750/90000 [=====>........................] - ETA: 8907s - loss: 3.9299 - acc: 0.255721000/90000 [======>.......................] - ETA: 8877s - loss: 3.9164 - acc: 0.257821250/90000 [======>.......................] - ETA: 8843s - loss: 3.9048 - acc: 0.259721500/90000 [======>.......................] - ETA: 8812s - loss: 3.8916 - acc: 0.261921750/90000 [======>.......................] - ETA: 8779s - loss: 3.8801 - acc: 0.263722000/90000 [======>.......................] - ETA: 8747s - loss: 3.8701 - acc: 0.265422250/90000 [======>.......................] - ETA: 8714s - loss: 3.8585 - acc: 0.267122500/90000 [======>.......................] - ETA: 8681s - loss: 3.8440 - acc: 0.269922750/90000 [======>.......................] - ETA: 8648s - loss: 3.8302 - acc: 0.272223000/90000 [======>.......................] - ETA: 8612s - loss: 3.8179 - acc: 0.274123250/90000 [======>.......................] - ETA: 8581s - loss: 3.8031 - acc: 0.276723500/90000 [======>.......................] - ETA: 8549s - loss: 3.7885 - acc: 0.279123750/90000 [======>.......................] - ETA: 8515s - loss: 3.7760 - acc: 0.281024000/90000 [=======>......................] - ETA: 8483s - loss: 3.7631 - acc: 0.283124250/90000 [=======>......................] - ETA: 8449s - loss: 3.7489 - acc: 0.285624500/90000 [=======>......................] - ETA: 8418s - loss: 3.7365 - acc: 0.287324750/90000 [=======>......................] - ETA: 8388s - loss: 3.7259 - acc: 0.288825000/90000 [=======>......................] - ETA: 8357s - loss: 3.7122 - acc: 0.291225250/90000 [=======>......................] - ETA: 8324s - loss: 3.7016 - acc: 0.293225500/90000 [=======>......................] - ETA: 8294s - loss: 3.6903 - acc: 0.295125750/90000 [=======>......................] - ETA: 8265s - loss: 3.6785 - acc: 0.297026000/90000 [=======>......................] - ETA: 8235s - loss: 3.6666 - acc: 0.299026250/90000 [=======>......................] - ETA: 8205s - loss: 3.6541 - acc: 0.301426500/90000 [=======>......................] - ETA: 8170s - loss: 3.6448 - acc: 0.303126750/90000 [=======>......................] - ETA: 8137s - loss: 3.6341 - acc: 0.305027000/90000 [========>.....................] - ETA: 8105s - loss: 3.6249 - acc: 0.306427250/90000 [========>.....................] - ETA: 8072s - loss: 3.6156 - acc: 0.307727500/90000 [========>.....................] - ETA: 8040s - loss: 3.6057 - acc: 0.309327750/90000 [========>.....................] - ETA: 8007s - loss: 3.5945 - acc: 0.311228000/90000 [========>.....................] - ETA: 7974s - loss: 3.5840 - acc: 0.313228250/90000 [========>.....................] - ETA: 7941s - loss: 3.5729 - acc: 0.315428500/90000 [========>.....................] - ETA: 7899s - loss: 3.5643 - acc: 0.316828750/90000 [========>.....................] - ETA: 7859s - loss: 3.5547 - acc: 0.318429000/90000 [========>.....................] - ETA: 7820s - loss: 3.5433 - acc: 0.320329250/90000 [========>.....................] - ETA: 7780s - loss: 3.5333 - acc: 0.322029500/90000 [========>.....................] - ETA: 7740s - loss: 3.5244 - acc: 0.323329750/90000 [========>.....................] - ETA: 7699s - loss: 3.5152 - acc: 0.324930000/90000 [=========>....................] - ETA: 7658s - loss: 3.5057 - acc: 0.326530250/90000 [=========>....................] - ETA: 7616s - loss: 3.4969 - acc: 0.328230500/90000 [=========>....................] - ETA: 7574s - loss: 3.4860 - acc: 0.330130750/90000 [=========>....................] - ETA: 7533s - loss: 3.4750 - acc: 0.332131000/90000 [=========>....................] - ETA: 7491s - loss: 3.4653 - acc: 0.333831250/90000 [=========>....................] - ETA: 7451s - loss: 3.4552 - acc: 0.335631500/90000 [=========>....................] - ETA: 7411s - loss: 3.4459 - acc: 0.337431750/90000 [=========>....................] - ETA: 7372s - loss: 3.4368 - acc: 0.338932000/90000 [=========>........