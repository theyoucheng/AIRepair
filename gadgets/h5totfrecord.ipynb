{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "215cd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ab28e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "540bfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47e70e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_weights', 'backend', 'keras_version', 'model_config'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata = dd.io.load(\"fmnist_simple.h5\")\n",
    "mydata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69bbb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(example):\n",
    "    \"\"\"Serialize an item in a dataset\n",
    "    Arguments:\n",
    "      example {[list]} -- list of dictionaries with fields \"name\" , \"_type\", and \"data\"\n",
    "\n",
    "    Returns:\n",
    "      [type] -- [description]\n",
    "    \"\"\"\n",
    "    dset_item = {}\n",
    "    for feature in example.keys():\n",
    "        dset_item[feature] = example[feature][\"_type\"](example[feature][\"data\"])\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=dset_item))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0073854",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'float32_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;66;03m# just a progressbar\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m n_observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mmydata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# how many items are in your dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# loop through hdf5 of examples, save to tfrecord\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mTFRecordWriter(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyfile.tfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# for each example\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'float32_labels'"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm # just a progressbar\n",
    "n_observations = len(mydata[\"float32_labels\"])  # how many items are in your dataset\n",
    "# loop through hdf5 of examples, save to tfrecord\n",
    "with tf.io.TFRecordWriter(str('myfile.tfrecord')) as writer:\n",
    "    # for each example\n",
    "    for exi in tqdm(range(n_observations)):\n",
    "        # create an item in the datset converted to the correct formats (float, int, byte)\n",
    "        example = serialize_example(\n",
    "            {\n",
    "                \"float32_labels\": {\n",
    "                    \"data\": mydata[\"float32_labels\"][exi],\n",
    "                    \"_type\": _float_feature,\n",
    "                },\n",
    "                \"int64_labels\": {\n",
    "                    \"data\": mydata[\"int64_labels\"][exi],\n",
    "                    \"_type\": _int64_feature,\n",
    "                },\n",
    "                \"text_labels\": {\n",
    "                    \"data\": np.string_(mydata[\"text_labels\"][exi]).astype(\"|S7\"),\n",
    "                    \"_type\": _bytes_feature,\n",
    "                },\n",
    "                \"train_images\": {\n",
    "                    \"data\": mydata[\"train_images\"][exi].flatten().tobytes(),\n",
    "                    \"_type\": _bytes_feature,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        # write the defined example into the dataset\n",
    "        writer.write(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
